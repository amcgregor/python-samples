{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    "There are a number of generalized steps in processing various text values.\n",
    "\n",
    "\n",
    "## Unicode Normalization\n",
    "\n",
    "Unicode encoding supports a number of \"normal forms\" and the concept of [\"Unicode equivalence\"](https://en.wikipedia.org/wiki/Unicode_equivalence). In order to make simple comparisons between strings possible, and efficient, all strings involved should be [normalized](https://en.wikipedia.org/wiki/Text_normalization) to a known standard, either combined (utilizing characters / code points that combine accents with the letter they modify) or utilizing [combining characters](https://en.wikipedia.org/wiki/Combining_character).\n",
    "\n",
    "Additionally, there is an excellent library called [FTFY](https://ftfy.readthedocs.org/) (it _Fixes Text For You_) that can resolve incorrect decoding referred to as [mojibake](https://en.wikipedia.org/wiki/Mojibake), and other issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from unicodedata import combining, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uninorm(value:Union[bytes,str], encoding:str='utf8', fallback:str='Windows-1252') -> str:\n",
    "\tif isinstance(value, bytes):\n",
    "\t\ttry:\n",
    "\t\t\tvalue = value.decode(encoding)\n",
    "\t\texcept UnicodeDecodeError:\n",
    "\t\t\tvalue = value.decode(fallback)\n",
    "\t\n",
    "    # value = fix_text(value)  # If utilizing the excellent FTFY library.\n",
    "\tvalue = normalize('NFC', value)  # Combined form.\n",
    "\tvalue = value.replace('\\r\\n', '\\n')  # Also eliminate extraneous Windows end-of-line markers.\n",
    "\t\n",
    "\treturn value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating Combining Characters\n",
    "\n",
    "Sometimes you just want ASCII out the other side. However, most \"accented\" characters can be represented without their accent without too much loss of fidelity; wetware is quite good at correcting minor deficciencies like that. Luckily, by decomposing into a combining character form we can very easily run through the resulting characters and throw away those identified as combining.\n",
    "\n",
    "This has the added benefit of eliminating most \"[Zalgo text](https://en.wikipedia.org/wiki/Combining_character#Zalgo_text)\", a disruptive abuse of stackable combining characters to force rendering to escape a container and obscure surrounding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noncombining(value:str) -> str:\n",
    "\treturn \"\".join(c for c in normalize('NFKD', value) if not combining(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice Zoe Bevan-McGregor'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncombining(\"Alice Zoë Bevan-McGregor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL-Safe \"Slugification\"\n",
    "\n",
    "An extremely common pattern is that of \"slugification\", that is, transforming a textual label into a value suitable for use within a URI, e.g. as a path element. Typically used to support \"SEO-friendly URLs\" where the address can be memorable and not just an abstract identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import compile as re, Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urlsafe(name:str, collection:List[str]=[], replacement:str='-', unsafe:Pattern=re(r'\\W+')) -> str:\n",
    "    base = unsafe.sub(replacement, uninorm(name)).strip(replacement)\n",
    "    suffix = 0\n",
    "    \n",
    "    while True:\n",
    "        if (result := f\"{base}{replacement if suffix else ''}{suffix if suffix else ''}\") not in collection:\n",
    "            break\n",
    "        suffix += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice-Zoë-Bevan-McGregor'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlsafe(\"Alice Zoë Bevan-McGregor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Words-2'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you have a collection of values, to ensure collisions are avoided, pass it in.\n",
    "urlsafe(\"Words\", [\"Words\", \"Words-1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
